#!/bin/bash
set -e
##### LOVEY-STATS
# This script was coded to create download statistics from S3 bucket logs.
# It pulls logfiles from a bucket, filters out unnecessary log entries, 
# converts the remaining entries to NCSA CLF, then feeds it to Webalizer.
# In my personal setup, this script is set to run in a cron job every day
# on a Raspberry Pi (v1 Model B). All you have to do is set up a web server 
# on the Pi and you have free, current download statistics for your bucket!

# Get stats for $DATE (default: yesterday)
DATE="$(date --date="yesterday" +"%F")"
if [ ! -z "$1" ]; then
    DATE="$1"
fi

# S3 Bucket name from which you want to pull logfiles
BUCKETNAME="lovey-dummies"

# Point this to your designated log directory
LOGDIR="$(pwd)"

# Set up various logfiles
TMPLOG="$LOGDIR/tmp.log"
PRSLOG="$LOGDIR/aws.log"
CMDLOG="$LOGDIR/command.log"

# Set "LogFile" in your webalizer.conf to $ACCLOG
ACCLOG="$LOGDIR/access.log"

# If we're starting a new month, or we explicitly set the
# date, rotate some logs
DTEST="$(echo "$DATE" | cut -d "-" -f 3)"
if [ ! -z "$1" ] || [ "$DTEST" -lt 2 ]; then
    true > "$CMDLOG"
    true > "$ACCLOG"
fi

{
  echo "-----------------------------------"
  echo "LOVEY-STATS START: $(date)"
  echo "Date set to $DATE"
  echo "-----------------------------------"
  echo "Pulling logs from S3..."
} >> "$CMDLOG"

# Pull down logs from S3
aws s3 cp "s3://$BUCKETNAME/logs/" "$LOGDIR/" \
    --recursive --exclude "*" --include "$DATE*" >> "$CMDLOG" && sync

{
  echo "--------"
  echo "Aggregating and filtering S3 logs..."
} >> "$CMDLOG"

# Aggregate S3 logs into one file, filter out unnecessary entries
for i in $LOGDIR/*; do cat "$i" >> "$TMPLOG"; done && sync
cat "$TMPLOG" | grep "REST.GET.OBJECT" \
              | grep -v "user/David" \
              | grep -v localhost \
              | grep -v "S3Console" \
              | grep -v "ld-cover.png" \
              | grep -v "$BUCKETNAME/logs" \
              | grep -v "$BUCKETNAME/blog" \
              | grep -v "$BUCKETNAME/social" \
              > "$PRSLOG" && sync

cat "$PRSLOG" >> "$CMDLOG"

{
  echo "--------" >> "$CMDLOG"
  echo "Converting S3 Log Format into NCSA Combined Log Format..."
} >> "$CMDLOG"

# Turn S3 Server Access Log Format into NCSA CLF
while IFS= read -r LINE; do
    remote_ip=$(echo "$LINE" | cut -d ' ' -f 5)
    dash="-"
    request_date=$(echo "$LINE" | cut -d ' ' -f 3-4)
    request_uri=$(echo "$LINE" | cut -d ' ' -f 10-12)
    http_status=$(echo "$LINE" | cut -d ' ' -f 13)
    bytes_sent=$(echo "$LINE" | cut -d ' ' -f 15)
    referrer=$(echo "$LINE" | cut -d ' ' -f 19)
    user_agent=$(echo "$LINE" | cut -d '"' -f 6)

    {
      printf "%s " "$remote_ip"
      printf "%s " "$dash"
      printf "%s " "$dash"
      printf "%s " "$request_date"
      printf "%s " "$request_uri"
      printf "%s " "$http_status"
      printf "%s " "$bytes_sent"
      printf "%s " "$referrer"
      printf "%s\n" "\"$user_agent\""
    } >> "$ACCLOG" && sync

    {
      printf "%s " "$remote_ip"
      printf "%s " "$dash"
      printf "%s " "$dash"
      printf "%s " "$request_date"
      printf "%s " "$request_uri"
      printf "%s " "$http_status"
      printf "%s " "$bytes_sent"
      printf "%s " "$referrer"
      printf "%s\n" "\"$user_agent\""
    } >> "$CMDLOG" && sync
done < "$PRSLOG"

# Remove unnecessary logfiles
rm "$TMPLOG" "$PRSLOG" "$LOGDIR/$DATE"*

{
  echo "--------"
  echo "Running The Webalizer on new data..."
} >> "$CMDLOG"

# Run The Webalizer for generating stats
webalizer >> "$CMDLOG" 2>&1

{
  echo "----------------"
  echo "LOVEY-STATS FINISH: $(date)"
} >> "$CMDLOG"
